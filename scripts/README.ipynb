{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create --name recipe1m pytorch=3\n",
    "sorce activate recipe1m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train用データの用意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生データの用意\n",
    "`layer1.json` （`ingredients`, `partition`, `title`, `id`, `instructions`）、 <br>\n",
    "`layer2.json` （`id`、 `images`）、<br>\n",
    "`det_ingrs.json` （`valid`、 `id`、 `ingredients`） を用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SUFFIX = \"test\"\n",
    "DATA_PATH = \"../data/\" + SUFFIX + '/'\n",
    "os.environ['DATA_PATH'] = DATA_PATH\n",
    "os.environ['SUFFIX'] = SUFFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigram の生成\n",
    "料理名 title について、頻度順のbi-gram (`bigram-suffix.pkl`） と 料理名一覧（`titles-suffix.txt`） を生成\n",
    "\n",
    "`scipy` のバージョンが 1.1.0 である必要がある。JupyterLab　上ではうまく動かなかったので、これはターミナル上で叩くことにした <br>\n",
    "→ 動かしたいカーネル上で jupyter-lab　を起動したら無事うまくいくようになった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "Loading dataset.\n",
      "Creating bigrams...\n"
     ]
    }
   ],
   "source": [
    "!python bigrams.py --crtbgrs -dataset=$DATA_PATH -suffix=$SUFFIX\n",
    "python bigrams.py --crtbgrs -dataset=../data/test/ -suffix=test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vecのtrain\n",
    "料理手順 instructions について、token化した上でword2vecをtrainする。 <br>\n",
    "\n",
    "### tokenize\n",
    "`layer1.json`　の instructions を token化。 `tokenized_instructions_train.txt` を生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tokenized here: ../data/test/tokenized_instructions_train.txt\n",
      "1400it [00:00, 97870.36it/s]\n",
      "0.03250312805175781 seconds.\n",
      "Number of unique ingredients 1936\n",
      "Saving tokenized here: ../data/test/tokenized_instructions_val.txt\n",
      "1400it [00:00, 385429.97it/s]\n",
      "0.013836383819580078 seconds.\n",
      "Number of unique ingredients 751\n",
      "Saving tokenized here: ../data/test/tokenized_instructions_test.txt\n",
      "1400it [00:00, 391781.80it/s]\n",
      "0.013638734817504883 seconds.\n",
      "Number of unique ingredients 747\n"
     ]
    }
   ],
   "source": [
    "!python tokenize_instructions.py -dataset=$DATA_PATH -partition=train\n",
    "!python tokenize_instructions.py -dataset=$DATA_PATH -partition=val\n",
    "!python tokenize_instructions.py -dataset=$DATA_PATH -partition=test\n",
    "\n",
    "python tokenize_instructions.py -dataset=../data/test/ -partition=train\n",
    "python tokenize_instructions.py -dataset=../data/test/ -partition=val\n",
    "python tokenize_instructions.py -dataset=../data/test/ -partition=test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n",
    "`tokenized_instructions_train.txt` を用いてword2vecのtrain。 `vocab.bin` を生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ~/workspace/joint-embedding/im2recipe-Pytorch/scripts\n",
    "# !wget https://storage.googleapis.com/google-code-archive-source/v2/code.google.com/word2vec/source-archive.zip\n",
    "# !unzip source-archive.zip\n",
    "# !cd word2vec/trunk/\n",
    "# !make word2vec # なんかこれもターミナルでやったらできた\n",
    "!mv word2vec/ _word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file ../data/test/tokenized_instructions_train.txt\n",
      "Vocab size: 733\n",
      "Words in train file: 112025\n"
     ]
    }
   ],
   "source": [
    "!cd ~/workspace/joint-embedding/im2recipe-Pytorch/scripts\n",
    "os.environ['SOURCE'] = DATA_PATH + \"tokenized_instructions_train.txt\"\n",
    "os.environ['TARGET'] = DATA_PATH + \"vocab.bin\"\n",
    "!./_word2vec/trunk/word2vec -hs 1 -negative 0 -window 10 -cbow 0 -iter 10 -size 300 -binary 1 -min-count 20 -threads 20 -train $SOURCE -output $TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocab の確認\n",
    "`vocab.bin` を可視化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ../data/test/vocab.txt...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "os.environ['VOCAB'] = DATA_PATH + \"vocab.txt\"\n",
    "os.environ['TARGET'] = DATA_PATH + \"vocab.bin\"\n",
    "!python get_vocab.py $TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classes.pkl の生成\n",
    "`food101_classes_renamed.txt` が見つからなかったので、 `food_classes.txt` を利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "Loading dataset.\n",
      "Loading ingr vocab.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "!python bigrams.py --nocrtbgrs -dataset=$DATA_PATH -suffix=$SUFFIX -vocab=$VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instructions の embedding\n",
    "`layer1.json` の `instructions` について skip-thoughts でベクトル化したもの = `skip-instructions` を生成するのだが、Pytorchのコードが公開されていないため、BERTによるembeddingに置き換える。<br>\n",
    "GPUサーバにログインして以下を実行。必要があればDATASETのPATHをファイルを直接書き換えて変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run on GPU\n",
    "!bert-embedding.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make LMDB\n",
    "mk_dataset.py は parameter 参照時に ../args.py を見ているので注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "Loading skip-thought vectors...\n",
      "Traceback (most recent call last):\n",
      "  File \"mk_dataset.py\", line 68, in <module>\n",
      "    st_vecs_train = get_st('train')\n",
      "  File \"mk_dataset.py\", line 37, in get_st\n",
      "    info = pickle.load(f)\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/storage.py\", line 134, in _load_from_bytes\n",
      "    return torch.load(io.BytesIO(b))\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 529, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 702, in _legacy_load\n",
      "    result = unpickler.load()\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 665, in persistent_load\n",
      "    deserialized_objects[root_key] = restore_location(obj, location)\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 156, in default_restore_location\n",
      "    result = fn(storage, location)\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 132, in _cuda_deserialize\n",
      "    device = validate_cuda_device(location)\n",
      "  File \"/home/acb11910at/anaconda3/envs/scipy/lib/python3.7/site-packages/torch/serialization.py\", line 116, in validate_cuda_device\n",
      "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
      "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    }
   ],
   "source": [
    "### Run on GPU\n",
    "!python mk_dataset.py --bert --dataset=$DATA_PATH --suffix=SUFFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "python train.py <br>\n",
    "--img_path /path/to/images/ <br>\n",
    "--data_path /path/to/lmdbs/ <br>\n",
    "--ingrW2V /path/to/w2v/vocab.bin <br>\n",
    "--snapshots snapshots/ <br>\n",
    "--valfreq 10 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrsh -g gcb50373 -l rt_G.small=1 -l h_rt=01:00:00\n",
    "conda activate scipy\n",
    "cd workspace/joint-embedding/im2recipe-Pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 作ったLMDBで実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run on GPU\n",
    "python train.py \\\n",
    "--img_path /groups1/gcb50373/dataset/recipe1M/origin/images/ \\\n",
    "--data_path data/test/ \\\n",
    "--ingrW2V data/test/vocab.bin \\\n",
    "--snapshots snapshots/ \\\n",
    "--stDim 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### エラーメッセージの内容\n",
    "/tmp/pip-req-build-ufslq_a9/aten/src/THC/THCTensorIndex.cu:361: void indexSelectLargeIndex(TensorInfo<T, IndexType>, TensorInfo<T, IndexType>, TensorInfo<long, IndexType>, int, int, IndexType, IndexType, long) [with T = float, IndexType = unsigned int, DstDim = 2, SrcDim = 2, IdxDim = -2, IndexIsMajor = true]: block: [210,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. ダウンロードしたLMDBで実験\n",
    "前やった時はできなかったはずなのに動いた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py \\\n",
    "--img_path /groups1/gcb50373/dataset/recipe1M/origin/images/ \\\n",
    "--data_path /groups1/gcb50373/dataset/recipe1M/origin/lmdb/ \\\n",
    "--ingrW2V /groups1/gcb50373/dataset/recipe1M/origin/vocab.bin \\\n",
    "--snapshots snapshots/ \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scipy",
   "language": "python",
   "name": "scipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
